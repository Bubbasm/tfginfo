PENDIENTE

    Utilidad de serie de la primera diferencia para eliminar la tendencia. "aceleración de los datos". ¿Y si la tendencia no es lineal? ¿Esto permitiría quitar la tendencia sin usar los polinomios? ¿Es alfa estable el resultado? -> Parece que sí quita la tendencia con la primera diferencia. A simple vista, parece que la diferenciación elimina el ataque, pero hay que calcular los parámetros de la distribución para ver si realmente es apreciable o no la diferencia. ¿Afecta a la asimetría? ¿A la curtosis? ¿A la varianza? -> Parece que la media y desviación sí varían con el ataque respecto a cuando no lo hay. Adicionalmente, parece que la distribución pasa a ser multimodal, pero no siempre.
        Repartir entrenamiento y pruebas en ventanas disjuntas para que no haya filtración de datos entre una y la otra. -> Revisarlo, que no está claro que sean completamente disjuntas todavía (descartando ¿900? puntos delante y detrás).
        Mirar si usar percentiles (90 y 95) de cada ventana puede mejorar la clasificación.
    Plantear esquema de TFM.  -> Revisar índice según lo comentado en la tutoría

REALIZADO

    ¿A partir de qué grado del polinomio se pasa el test ADF? -> Calculado test ADF para ventanas de distinto tiempo. Revisar en qué caso se pasa y en qué caso no. ¿Por qué se pasa con ventana de un día? -> Pasa con grado 6 para 15 min, grado 8 para 30 min, de grado 7 para 45 min, de grado 9 para 1 hora. Para 1, 2 y 6 días, pasa sin necesidad de polinomio. El test ADF solo dice si existe una raíz unitaria, que es una condición necesaria, pero no suficiente, para estacionareidad.
    Probar también el KPSS. ¿Cuál es la tendencia que se usa para el KPSS? -> Es una hipótesis contraria: si se rechaza, no es estacionaria. Se rechaza para todos menos para 5 min.
    ¿Se puede predecir hacia delante usando otro modelo? (seasonal decompose, H-W, Wavelets, Fourier, FDA, etc.) 
        Comparar y ver qué sale mejor. -> H-W predice mejor cuanto más datos previos tiene. Poniendo la beta (parámetro para regular la tendencia previa) a 0 la predicción es mejor (tener siempre en cuenta la tendencia original). 
        Seasonal decompose: Estadístico Epps-Singleton, comparar si tienen la misma distribución y test K-S. En ambos casos sale p-valor=0 (no son la misma distribución que el día)-> Mirar con ventanas más pequeñas.
    Revisar simulated annealing y descenso del gradiente para hacerlo. -> Depende del periodo de tiempo que se esté utilizando para obtener los valores de alfa, beta y gamma. No salen valores que sean estables. -> Combinar predicción a largo y corto plazo. Análisis multiresolución (wavelets). ¿Qué tiene por debajo el seasonal_decompose de Python? -> Sesaonal decompose descompone utilizando medas móviles. -> Analizar el residuo en escala semanal y diaria, y ver los parámetros alfaestables en ventanas de 15 minutos que se van desplazando un tiempo configurable (t=1, 60 o 900). Hay un mutiple-seasonality, probar también. -> el multiple tarda tanto que no acaba nunca. La biblioteca de python para hacer el fit tarda mucho tiempo. Calculando doble seasonal_decompose en semana y hora, parece que la semana ya da una idea de cómo se comporta cada día, y el diario. Probar con cada ventana de 15 minutos (al menos 4 ventanas a la hora) a partir de las 2 semanas previas con ventanas de la semana siguiente. Probar con test de contraste, pero en general me da que no va a dar resultado, pues las distribuciones varían mucho.
    Pregunta de investigación: ¿Cómo se quita la estacionalidad en estadística habitualmente?
        Revisar seasonality y desestacionalizar. 
    Revisar ARIMA, pero probablemente no vaya mejor que Holt-Winters.
    Revisar Prophet. -> Un primer test predice en un rango divergente (pero es que es varios años de predicción). Me recuerda a lo que se hace para la predicción de defunciones en MOMO del ISCIII: Sería adecuado tener una línea base con un intervalo de confianza del 1 al 99%.
    Ver que al quitar el polinomio mejora la distancia a la distribución ajustada.
    [TFG]: Definir título y asignar en la plataforma.  "Aplicación de técnicas de análisis de series temporales a tráfico de red" 
    Si lo de la derivada funciona, plantearse una derivada mejor, con una convolución [-1/2, 0, 1/2]. -> Saca resultados parecidos. Probar a pintar también las distribuciones de media y de alfa-estables, por si tuviera alguna mejora. -> Parece que mejora. 
    Representar las medias de tráfico normal y con ataque, deberían salir dos gaussianas (o parecido) lo suficientemente separadas para usar un decisor binario para clasificar.
    Ver normalización -> Pendiente normalización de gamma (sigma) y delta (mu). -> Hecho 
    Ver regresión sobre los parámetros alfa estables -> A falta de revisar la delta, no parece que vaya mejor que la simple media.  -> Mejora un poquito, ver siguiente punto.
    Hacer validación cruzada si hubiera pocos días disponibles. -> Sale un F1 sale aproximadamente de 0,82 usando todos los parámetros (alfa-estables y media/desviación), y solo con media, 0,79. Ambos con regresión logística.  Solo delta y media es 0,80.  
    Hacer ajuste a Alfaestable con y sin ataque, para ver variaciones en los parámetros alfa (curtosis), beta (asimetría), mu y sigma. -> Revisar caso de delta, que no debería haber esa variación tan fuerte en altura en el histograma. -> Normalizando el histograma ya sale bien, y es peor que la media. 
    Ver si SVM mejora algo. -> Hecho con media y desviación típica. -> Ver precision, recall y F1-score de los distintos kérneles, para ver si realmente el lineal es suficiente o no. Ver también SVM con la combinación de parámetros alfa-estables. -> Pendiente de hacerlo funcionar. Probar con menos datos, por si fuera que se "atraganta". -> No va mejor usando delta y media 